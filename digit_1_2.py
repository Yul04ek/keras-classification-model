# -*- coding: utf-8 -*-
"""Копія записника "digit_1"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12sAMnlYbG2ec_UhsnixZUzYKxKYw0iuk
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

digit_recognizer_path = kagglehub.competition_download('digit-recognizer')

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

df_test = pd.read_csv("/kaggle/input/digit-recognizer/test.csv")
df_train = pd.read_csv("/kaggle/input/digit-recognizer/train.csv")
sample_submission = pd.read_csv("/kaggle/input/digit-recognizer/sample_submission.csv")

df_train.head()

sample_submission.head()

df_train.isna().sum().sort_values(ascending = False)

df_train.describe()

df_train[(df_train.iloc[:, 1: ]==0).all(axis=1)]

df_train['label'].value_counts().sort_index().plot(kind='bar', color='skyblue')
plt.title('Розподіл класів у df_train')

import random

def draw_digit(label, image):
    plt.imshow(image, cmap='gray')
    plt.title(f"Label: {label}")
    plt.axis('off')
    plt.show()

# Choosing random indices
random_indices = random.sample(range(len(df_train)), 3)

# We draw
for i in random_indices:
    draw_digit(df_train.iloc[i, 0], df_train.iloc[i, 1:].values.reshape(28, 28))

import keras
from tensorflow.keras.layers import Dropout
from tensorflow.keras import regularizers
from keras import layers

# Determining the number of features
num_features = df_train.shape[1]-1
print(num_features)

# Model creation
def uncompiled_model():
    model = keras.Sequential([
        keras.Input(shape=(28, 28, 1), name="input_layer"),

        layers.Conv2D(32, (3, 3), name="conv1"),
        layers.BatchNormalization(name="bn1"),
        layers.Activation('relu', name="relu1"),
        layers.MaxPooling2D((2, 2), name="pool1"),

        layers.Conv2D(64, (5, 5), padding='same', name="conv2"),
        layers.BatchNormalization(name="bn2"),
        layers.Activation('relu', name="relu2"),
        layers.MaxPooling2D((2, 2), name="pool2"),

        layers.Flatten(name="flatten"),

        layers.Dense(256, name="hidden_layer"),
        layers.BatchNormalization(name="bn3"),
        layers.Activation("relu", name="relu3"),

        layers.Dense(10, activation="softmax", name="output_layer")
    ])


    return model
uncompiled_model().summary()

# Model compilation
def get_compiled_model (optimizer="RMSprop",    loss='sparse_categorical_crossentropy', metrics=["sparse_categorical_accuracy"]):
    model = uncompiled_model()
    model.compile(optimizer=optimizer,  loss=loss,  metrics=metrics )
    return model

from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping
#  Data
X = df_train.drop('label',axis=1)
y= df_train['label']
X_train, X_test, y_train, y_test = train_test_split(X, y , random_state = None, test_size=0.2)
X_train = X_train.to_numpy().reshape(-1, 28, 28, 1).astype("float32") / 255.0
X_test = X_test.to_numpy().reshape(-1, 28, 28, 1).astype("float32") / 255.0
df_test = df_test.to_numpy().reshape(-1, 28, 28, 1).astype("float32") / 255.0

#  EarlyStopping
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)
#   Model training Навчання моделі
model = get_compiled_model()
history = model.fit(
    X_train, y_train,
    validation_split=0.2,       #  потрібно для val_loss
    batch_size=64,
    epochs=45,
    callbacks=[early_stop]      #  додаємо EarlyStopping
)

#  Rating
results = model.evaluate(X_test, y_test)

print("Loss:", results[0])
print("Accuracy:", results[1])

def generate_prediction(model, x_data, save_csv=False, filename='submission.csv'):
    """
    Predict the model on x_data (can be X_test or df_test).

  Parameters:
  model: trained Keras model
  x_data: DataFrame or pixel array
  save_csv: whether to save the result to CSV
  filename: filename to save
  Returns:
  pred_labels: array of predicted labels
    """
    # Convert to NumPy if it is a DataFrame
    if isinstance(x_data, pd.DataFrame):
        x_data = x_data.to_numpy()

    # predict
    y_pred_probs = model.predict(x_data)
    y_pred_labels = y_pred_probs.argmax(axis=1)

    # If necessary, save CSV
    if save_csv:
        submission = pd.DataFrame({
            'ImageId': range(1, len(y_pred_labels) + 1),
            'Label': y_pred_labels
        })
        submission.to_csv(filename, index=False)
        print(f"✅ Submission saved to {filename}")

    return y_pred_labels

predicted_digits = generate_prediction(model, X_test)

print(predicted_digits)

from sklearn.metrics import classification_report

y_pred = model.predict(X_test).argmax(axis=1)
print(classification_report(y_test, y_pred))

# Choosing random indices
random_indices = random.sample(range(len(X_test)), 3)

# We draw
for i in random_indices:
    draw_digit(y_pred[i], X_test[i].squeeze() )

y = generate_prediction(model, df_test, save_csv=True)
y

import datetime
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M")
model.save(f"my_model_{timestamp}.h5")

"""from tensorflow import keras
model = keras.models.load_model("my_model.h5")
"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()